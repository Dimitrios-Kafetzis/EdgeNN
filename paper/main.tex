\documentclass[11pt]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}           % Professional tables
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}           % Code listings
\usepackage{tikz}               % Architecture diagrams
\usepackage{pgfplots}           % Benchmark charts
\usepackage[ruled,vlined]{algorithm2e}  % Algorithm pseudocode
\usepackage{xcolor}
\usepackage{subcaption}         % Subfigures
\usepackage{url}
\usepackage{microtype}          % Improved typography
\usepackage{enumitem}           % List customization

% --- Hyperref (load last) ---
\usepackage[colorlinks=true,
            linkcolor=blue,
            citecolor=blue,
            urlcolor=blue]{hyperref}

% --- pgfplots compatibility ---
\pgfplotsset{compat=1.18}

% --- Code listing style ---
\lstdefinestyle{cstyle}{
    language=C,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{red},
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny\color{gray},
    breaklines=true,
    frame=single,
    captionpos=b,
    tabsize=4
}
\lstset{style=cstyle}

% --- Title and Author ---
\title{EdgeNN: A Quantization-First C Library for Deterministic \\
       DNN/RNN/Transformer Inference on ARM Microcontrollers}

\author{
    Dimitrios Kafetzis\textsuperscript{1,2} \\[4pt]
    \textsuperscript{1}DeepSea Technologies (Nabtesco subsidiary), IoT Department \\
    \textsuperscript{2}Athens University of Economics and Business, Department of Informatics \\[4pt]
    \texttt{dimitrioskafetzisd@gmail.com}
}

\date{\today}

% =================================================================
\begin{document}

\maketitle

% --- Abstract ---
\begin{abstract}
Deploying neural networks on ARM microcontrollers demands inference engines
that operate within tight memory budgets (64\,KB--2\,MB SRAM), deliver
deterministic latency for safety-critical applications, and avoid dynamic
memory allocation that introduces fragmentation and timing jitter.
%
Existing solutions either impose significant overhead (TensorFlow Lite
Micro, $\sim$100\,KB Flash), lack graph-level runtime capabilities
(CMSIS-NN), or require complex compiler toolchains unsuitable for
bare-metal deployment (microTVM).
%
Moreover, no current library provides unified operator coverage spanning
Dense/Convolutional, Recurrent (LSTM, GRU), and Transformer (Multi-Head
Attention) architectures---all within a zero-allocation execution model.

We present \textbf{EdgeNN}, a pure C11 library designed from the ground up
for deterministic neural network inference on ARM Cortex-M and Cortex-A
processors. EdgeNN employs a quantization-first design with INT8 symmetric
quantization, INT32 accumulation, and fixed-point requantization that
eliminates floating-point operations from the inference path. An arena-based
memory manager with a ping-pong buffer scheme provides zero-allocation
inference with bounded, predictable SRAM usage. EdgeNN implements 18
operators across DNN, RNN, and Transformer architectures, validated by 118
unit tests.

Preliminary evaluation on [target platform] demonstrates [X$\times$ speedup
/ Y\% Flash reduction / Z\% SRAM savings] compared to TensorFlow Lite
Micro, while maintaining less than 1 quantization step of accuracy
degradation. EdgeNN is open-source under the MIT License at
\url{https://github.com/Dimitrios-Kafetzis/EdgeNN}.
\end{abstract}

\textbf{Keywords:} edge inference, microcontroller, neural network,
quantization, ARM Cortex-M, LSTM, Transformer, embedded systems

% --- Sections ---
\input{sections/01_introduction}
\input{sections/02_related_work}
\input{sections/03_design_principles}
\input{sections/04_architecture}
\input{sections/05_operators}
\input{sections/06_quantization}
\input{sections/07_evaluation}
\input{sections/08_partitioning}
\input{sections/09_conclusion}

% --- References ---
\bibliographystyle{plain}
\bibliography{references}

% --- Appendix ---
\appendix
\input{sections/appendix}

\end{document}
